---
title: "Project 2--Modeling"
author: "Troy Miller"
date: '`r format(Sys.time(), "%A, %B %d, %Y @ %I:%M %p")`'
output: 
  html_document: 
    theme: yeti
    highlight: textmate
    code_folding: hide
---

```{r globalopts, include = FALSE}
library(knitr)
opts_chunk$set(comment = "", message = FALSE, warning = FALSE)
```

## {.tabset}

### **Packages/Data**

Load all packages and datasets here. Use `glimpse` to visualize the structure of each dataset.

Packages Used

```{r}
library(dplyr)
library(ggplot2)
library(tidyverse)
library(moments)
library(moderndive)
```

Fast Food Data

```{r fastfooddata}
ff <- read.csv("https://raw.githubusercontent.com/STAT-JET-ASU/Datasets/master/Instructor/fastfood2017.csv")
glimpse(ff)
```

Cookout Burgers Data

```{r cookoutdata}
ck <- read.csv("https://raw.githubusercontent.com/STAT-JET-ASU/Datasets/master/Instructor/cookoutburgers.csv")
glimpse(ck)
```

Spruce Experiment Data

```{r sprucedata}
spr <- read.csv("https://raw.githubusercontent.com/STAT-JET-ASU/Datasets/master/Chihara/Spruce.csv")
glimpse(spr)
```

Monopoly Game Data

```{r monopolydata}
mon <- read.csv("https://raw.githubusercontent.com/STAT-JET-ASU/Datasets/master/Instructor/monopolygame.csv")
glimpse(mon)
```


### **Problem 1**

Nutritionists recommend against eating fast food because it is high in sodium, saturated fat, trans fat, and cholesterol. Eating too much over a long period of time can lead to health problems such as high blood pressure, heart disease, and obesity. Many fast-food meals contain more than an entire day's worth of recommended calories! Read the description for the [`fastfood2017`](https://stat-jet-asu.github.io/Datasets/InstructorDescriptions/fastfood2017.html) dataset and the `cookoutburgers` dataset (on the same page), then use the data to perform the following analysis.

A) For fast-food burgers, create a correlation matrix for all of the nutritional variables except `servingsize`. Round the entries to two decimal places. Overall, how would you describe the relationships between nutritional components in fast-food burgers  (mostly weak, moderate, strong, varied)? Explain.

```{r burgercorr}
ff_1 <- ff %>%
  filter(type == "Burger")
ff_1 <- ff_1 %>%
  select(calories, totalfat, saturatedfat, transfat, sodium, carbs, sugars, protein)

round(cor(ff_1), 2)

```

**ANSWER:** Every relationship is at least moderately related with the lowest being .52 for saturated fat and carbs. Most relationships are very strong with total fat and calories having a .98 relationship.

B) Create a scatterplot with a fitted line to show the relationship between calories (x) and total fat (y) for fast-food burgers. Add an informative title and better axis labels than the default variable names, including units of measure.

```{r burgerplot}
ggplot(ff_1, aes(x = calories, y = totalfat)) +
 geom_point() +
  xlab("calories (cal)") +
  ylab("total fat (g)") +
  ggtitle("Relationship between calories and total fat for fast food burgers")  + geom_smooth(method = "lm", se = FALSE)
  

```

C) Fit a linear model to explore the relationship between calories (x) and total fat (y) for fast-food burgers. Display your model results using `get_regression_table()` and `get_regression_summaries()` with Markdown-formatted output. 

```{r burgermodel}
ff_lm <- lm(totalfat ~ calories, data = ff_1)
get_regression_table(ff_lm, print = TRUE)
get_regression_summaries(ff_lm)


```

D) Use your model and `get_regression_points()` to predict the total fat in the four Cookout burgers. Display the results with Markdown-formatted output. Compare these predictions to the actual total fat values in the `cookoutburgers` dataset. Did your model do a good job of predicting? Explain.

```{r burgerpred}
ff_rp <- get_regression_points(ff_lm, newdata = ck)
ff_rp
```

**ANSWER:** The model did well for predicting the total fat in the Cookout brugers, the worst guess was for burger 3, which was off by a around 7.4%.

E) Suppose someone says, "We can interpret R^2^ as the percentage of calories in each burger that comes from fat." Explain why this is incorrect and give a better interpretation of the R^2^ value for this model in context. 

**ANSWER:** No, the R-squared value is more a measure of how the fat is responsible for the variation in the amount of the calories in any burger.


### **Problem 2**

Case Study 1.10 in the MSRR textbook (p. 10) describes an experiment involving manipulations intended to impact the growth of black spruce seedlings. Load the data in [spruce.csv](https://raw.githubusercontent.com/STAT-JET-ASU/Datasets/master/Chihara/Spruce.csv) and perform the following analysis.

A) Once of the independent variables in the experiment was whether or not seedlings received fertilizer. Create a scatterplot with fitted lines to show the relationship between the heights of seedlings at the start of the experiment (x) and their heights after five years (y), with a separate line for the fertilized and not fertilized groups. Add an informative title and better axis labels than the default variable names, including units of measure.

```{r spruceplot}
ggplot(spr, aes(x = Height0, y = Height5, color = Fertilizer)) +
 geom_point() +
  xlab("Height at Start (cm)") +
  ylab("Height after 5 years (cm)") +
  ggtitle("Difference in height between fertilized and non-fertilized plants after 5 years") + geom_smooth(method = "lm", se = FALSE)

```

B) Fit a parallel slopes model to show the height of seedlings after five years as a function of starting height and fertilizer category. Display the `summary()` of your linear model. Interpret the values of the coefficients in context, including units.

```{r sprucemodel}
spr_lm <- lm(Height5 ~ Height0 + Fertilizer, data = spr)
summary(spr_lm)

```

**ANSWER:**

C) Use `get_regression_points()` to extract the fitted values and residuals from the model. Based on this information and other summary measures, do you think this model would do a good job of predicting the heights of other spruce seedlings grown under the same conditions? Explain.

```{r sprucepts}
get_regression_points(spr_lm)
```

**ANSWER:**


### **Problem 3**

First known as *The Landlord's Game* by its original developers, the game we now know as *Monopoly* was commercially released by Parker Brothers in 1935. There are now over 1000 variations of this classic game in the US and abroad. Read the description for the [`monopoly`](https://stat-jet-asu.github.io/Datasets/InstructorDescriptions/monopoly.html) dataset and use the data to perform the following analysis.

A) Create a scatterplot with fitted lines to show the relationship between the number of spaces from Go (x) and the purchase price of the property (y), with a separate line for each property type. Add an informative title and better axis labels than the default variable names, including units of measure. Would a parallel slopes model be appropriate here? Why or why not? (Note: It is possible to fit parallel slopes models with more than two categories by adding extra terms to the model, so the number of categories is not an issue.)

```{r pricesplot}
ggplot(mon, aes(x = spaces, y = cost, color = type)) +
 geom_point() +
  xlab("Spaces from go (#)") +
  ylab("Cost of property ($)") +
  ggtitle("Price of monopoly houses based on distance from Go") + geom_smooth(method = "lm", se = FALSE)

```

**ANSWER:** No, it would not be appropriate because the two parallel lines make up only 6 of many more properties, meaning you would not see the correct linear progression as there is no change in the price for these property types regardless of how far they are from Go

B) Fit a linear model that predicts property price as a function of spaces from Go for all the properties in the game (no groups). Display tables of coefficients and summaries for your model. 

```{r allpricemodel}
mon_reg <- lm(spaces ~ cost, data = mon)
get_regression_summaries(mon_reg)
get_regression_table(mon_reg)

```

C) Fit a linear model that predicts property price as a function of spaces from Go for the street properties only. Display tables of coefficients and summaries for your model. 

```{r streetpricemodel}
mon_1 <- mon %>%
  filter(type == "street")

mon_reg2 <- lm(spaces ~ cost, data = mon_1)
get_regression_summaries(mon_reg2)
get_regression_table(mon_reg2)

```

D) Discuss the differences between the your models (e.g., equations, R^2^ values, residuals, other relevant measures of fit). Why did taking out the railroads and utilities produce these changes?

**ANSWER:** Every type of measurement moved closer towards a linear model because those two types of properties had a wildly different pricing scheme from the rest the properties which made up the majority. R-Squared went from .771 to .989, mse went from 26.43 to 1.29, and standard error went from 2.667 to .63.

### Session Info

**Names of Collaborators**:

```{r}
sessionInfo()
```
